<!DOCTYPE html>
<html>
    <head>
        <title>Temario</title>
        <style>
            body {
                background-color: pink;
            }
            h1,h2 {
                text-align: center;
            }
            ul {
                background-color: #ffffff;
                padding: 10px;
                border-radius: 10px;
            }
        </style>
    </head>
    <body>
        <h1>TEMARIO</h1>

        <ul>
        <h2>Tema 1</h2>
        <h2>Estadística descriptiva.</h2>
        
            <li><h3>1.1 Conceptos básicos de estadística:</h3></li>
            <p>Estadística: Ciencia que se encarga de recopilar, organizar, analizar e interpretar datos.</p>
            <p>Teoría de decisión: Marco para la toma de decisiones óptimas en situaciones de incertidumbre.</p>
            <p>Población: Conjunto completo de elementos que se desea estudiar o analizar.</p>
            <p>Muestra aleatoria: Conjunto de elementos seleccionados de una población de manera que cada uno tiene la misma probabilidad de ser elegido.</p>
            <p>Parámetros aleatorios: Características o atributos de una población que pueden variar de manera aleatoria.</p>

            <li><h3>1.2 Descripción de datos:</h3></li>
            <p>Datos agrupados: Datos organizados en intervalos o clases.</p>
            <p>Datos no agrupados: Datos individuales, sin agrupar.</p>
            <p>Frecuencia de clase: Cantidad de elementos en cada intervalo o clase.</p>
            <p>Frecuencia relativa: Proporción de elementos en una clase respecto al total.</p>
            <p>Punto medio: Valor central de cada intervalo o clase.</p>
            <p>Límites: Valores que delimitan los intervalos o clases.</p>

            <li><h3>1.3 Medidas de tendencia central:</h3></li>
            <p>Media aritmética: Es el valor promedio de un conjunto de datos, calculado sumando todos los valores y dividiendo entre el número total de datos.</p>
            <p>Media geométrica: Es una media que se utiliza cuando los datos tienen gran variabilidad o se distribuyen de manera logarítmica, calculada como la raíz enésima del producto de todos los valores.</p>
            <p>Media ponderada: Es una media que asigna diferentes pesos o importancias a cada valor, calculada multiplicando cada valor por su peso correspondiente, sumando estos productos y dividiendo entre la suma de los pesos.</p>
            <p>Mediana: Valor central de un conjunto de datos ordenados.</p>
            <p>Moda: Valor que se repite con mayor frecuencia.</p>
            <p>Varianza y desviación estándar: Medidas de dispersión que indican cuánto se desvían los datos de la media.</p>
            <p>Desviación media y mediana: Medidas de dispersión basadas en diferencias absolutas.</p>
            <p>Rango: Diferencia entre el valor más alto y el más bajo.</p>

            <li><h3>1.4 Parámetros para datos agrupados:</h3></li>
            <p>Medidas de tendencia central y dispersión aplicadas a datos organizados en intervalos o clases.</p>

            <li><h3>1.5 Distribución de frecuencias:</h3></li>
            <p>Organización de datos en intervalos o clases con sus respectivas frecuencias.</p>

            <li><h3>1.6 Técnicas de agrupación de datos:</h3></li>
            <p>Métodos para agrupar datos en intervalos o clases, como reglas empíricas.</p>

            <li><h3>1.7 Técnicas de muestreo:</h3></li>
            <p>Procedimientos para seleccionar muestras representativas de una población.</p>
        </ul>


        <ul>
        <h2>Tema 2</h2>
        <h2> Fundamentos de la Teoría de Probabilidad.</h2>


             <li><h3>2.1 Técnicas de Conteo</h3></li>
             <p>Las técnicas de conteo son métodos matemáticos utilizados para determinar el número de posibles resultados o arreglos de un conjunto de 
             elementos. Estas técnicas permiten calcular el espacio muestral, es decir, el conjunto de todos los posibles resultados de un experimento o evento, lo cual es fundamental para el 
             análisis de probabilidad.
            </p>
          
            <li><h3>2.1.1 Principio aditivo.</h3></li>
            <p>Método para calcular el número total de posibles resultados de dos o más eventos mutuamente excluyentes, sumando las posibilidades de cada evento.</p>

            <li><h3>2.1.2 Principio multiplicativo. </h3></li>
            <p>Método para calcular el número total de posibles resultados de dos o más eventos independientes, multiplicando las posibilidades de cada evento.</p>
       
           <li><h3>2.1.3 Notación Factorial.</h3></li>
            <p>Representación matemática del producto de todos los números naturales desde 1 hasta un número dado, denotada como n!.</p>

            <li><h3>2.1.4 Permutaciones.</h3></li>
            <p>Arreglos ordenados de un conjunto de elementos, donde el orden de los elementos es relevante.</p>

    <li><h3>2.1.5 Combinaciones.</h3></li>
    <p>Formas de seleccionar un subconjunto de elementos de un conjunto, donde el orden de los elementos no es relevante.</p>

    <li><h3>2.1.6 Diagrama de Árbol. </h3></li>
    <p>Representación gráfica de las posibles secuencias de eventos, donde cada rama representa un posible resultado.</p>

    <li><h3>2.1.7 Teorema del Binomio.</h3></li>
    <p>Fórmula matemática que permite expandir potencias de expresiones binomiales, es decir, sumas de dos términos.</p>

    <li><h3>2.2 Teoría elemental de probabilidad.</h3></li>
    <p>Conjunto de conceptos y principios fundamentales que rigen el cálculo de probabilidades, como espacio muestral, eventos y sus operaciones.</p>

    <li><h3>2.3 Probabilidad de Eventos</h3></li>
    <p>Medida de la posibilidad de ocurrencia de un determinado suceso, definida a partir del espacio muestral y las operaciones con eventos como unión, intersección y complemento.</p>
    <p>Espacio muestral (Ω): El conjunto de todos los posibles resultados de un experimento o evento aleatorio.</p>
    <p>Evento (A): Cualquier subconjunto del espacio muestral, es decir, un conjunto de resultados que pueden ocurrir en un experimento.</p>
    <p>Simbología:</p>
    <ul>
        <li>Espacio muestral: Ω </li>
        <li>Evento: A, B, C, etc.</li>
        <li>Unión de eventos: A ∪ B</li>
        <li>Intersección de eventos: A ∩ B</li>
        <li>Complemento de un evento: A'</li>
    </ul>
    <p>Unión (A ∪ B): Conjunto de resultados que pertenecen a A o a B, o a ambos.</p>
    <p>Intersección (A ∩ B): Conjunto de resultados que pertenecen tanto a A como a B.</p>
    <p>Diagramas de Venn: Representación gráfica de las operaciones con eventos, donde los eventos se representan como conjuntos y las operaciones se visualizan mediante intersecciones y uniones de dichos conjuntos.</p>

    <li><h3>2.4 Probabilidad con Técnicas de Conteo</h3></li>
    <p>Aplicación de los métodos de conteo, como permutaciones y combinaciones, para calcular probabilidades de eventos.</p>                
    <p>Axiomas:</p>
    <p>Los axiomas básicos de probabilidad son:</p>
    <ul>
    <p>P(A) ≥ 0 para todo evento A (la probabilidad de cualquier evento es no negativa).</p>
    <p>P(Ω) = 1 (la probabilidad del espacio muestral completo es 1).</p>
    <p>Si A y B son eventos mutuamente excluyentes, entonces P(A ∪ B) = P(A) + P(B).  </p>
    </ul>                
    <p>Teoremas: Principales teoremas de probabilidad:</p>
    <ul>
        <p>Teorema de la Probabilidad Complementaria: P(A') = 1 - P(A)</p>
        <p>Teorema de la Probabilidad de la Unión: P(A ∪ B) = P(A) + P(B) - P(A ∩ B)</p>
        <p>Teorema de la Probabilidad de la Intersección: P(A ∩ B) = P(A|B) * P(B) = P(B|A) * P(A)</p>
    </ul>
    
    <li><h3>2.5 Probabilidad condicional.</h3></li>
    <p>Probabilidad de que ocurra un evento dado que otro evento ya ha ocurrido, es decir, la probabilidad de un evento condicionada a la ocurrencia de otro.</p>
    <p>Eventos Dependientes:</p>
    <ul>
        <p>Dos eventos A y B son dependientes si la ocurrencia de uno afecta la probabilidad del otro. Esto se cumple cuando:</p>
        <p>P(A|B) ≠ P(A) o P(B|A) ≠ P(B)</p>
    </ul>
    <p>Eventos Independientes:</p>
    <ul>
        <p>Dos eventos A y B son independientes si la ocurrencia de uno no afecta la probabilidad del otro. Esto se cumple cuando:</p>
        <p>P(A|B) = P(A) y P(B|A) = P(B)</p>
    </ul>
          
    <li><h3>2.6 Ley multiplicativa.</h3></li>
    <p>Principio que relaciona la probabilidad de la intersección de dos eventos con sus probabilidades individuales, estableciendo que la probabilidad de la intersección es igual al producto de las probabilidades de cada evento.</p>
    
    <li><h3>2.7 Eventos independientes</h3></li>
    <p>Eventos cuya ocurrencia no afecta la probabilidad de ocurrencia del otro, regulados por la Regla de Bayes, que permite calcular la probabilidad de un evento dado que otro ha ocurrido.</p>
    <p>Regla de Bayes:</p>
    <ul>
        <p>La Regla de Bayes es una herramienta fundamental para calcular probabilidades condicionales en situaciones de eventos dependientes. La fórmula de la Regla de Bayes es:</p>
        </p>P(A|B) = (P(B|A) * P(A)) / P(B)</p>
        <p>Donde:</p>
                        <p>P(A|B) es la probabilidad condicional de A dado B</p>
                        <p>(B|A) es la probabilidad condicional de B dado A</p>
                        <p>P(A) es la probabilidad marginal de A</p>
                        <p>P(B) es la probabilidad marginal de B</p>
    </ul>

</ul>

<ul>
<h2>Tema 3</h2>
<h2> Variables Aleatorias.</h2>

    <li><h3>3.1 Variables aleatorias discretas</h3>
    <p>Las variables aleatorias discretas son variables que pueden tomar un número finito o contable de valores. Algunos ejemplos de variables aleatorias discretas son:</p>
    <ul>
        <p>Número de caras en un lanzamiento de moneda</p>
        <p>Número de hijos en una familia</p>
        <p>Número de llegadas de clientes a una tienda en un día</p>
    </ul>

    <li><h3>3.1.1 Distribución de probabilidad en forma general.</h3>
    <p>La distribución de probabilidad de una variable aleatoria discreta es una función que asigna una probabilidad a cada posible valor de la variable.</p>

    <li><h3>3.1.2 Valor esperado</h3></li>
    <p>El valor esperado de una variable aleatoria discreta es el promedio ponderado de todos los posibles valores que puede tomar la variable, donde las ponderaciones son las probabilidades correspondientes.</p>
    
    <li><h3>3.1.3 Variancia, desviación estándar.</h3></li>
    <p>Variancia (Var(X)):La variancia de una variable aleatoria discreta X mide qué tan dispersos están los valores de X alrededor de su valor esperado E(X).</p>
    <p>Calcula como la suma de los cuadrados de las diferencias entre cada valor posible x y el valor esperado E(X), ponderados por las probabilidades p(x):</p>
    <ul>
        <p>Var(X) = Σ (x - E(X))^2 * p(x)</p>
        <p>La variancia siempre es un número no negativo.</p>
    </ul>
    <p>Desviación estándar (σ):</p>
    <p>La desviación estándar de una variable aleatoria discreta X se define como la raíz cuadrada positiva de la variancia:</p>  
    <ul>
        <p>σ = √Var(X)</p>
        <p>La desviación estándar tiene las mismas unidades que la variable X.</p>
        <p>Al igual que la variancia, la desviación estándar es una medida de dispersión. Mientras mayor sea σ, más dispersos estarán los valores en torno al valor esperado.</p>
        <p>La desviación estándar es útil para interpretar qué tan alejados están los valores de la variable aleatoria con respecto a su valor promedio.</p>
    </ul>

    <li><h3>3.1.4 Función acumulada.</h3></li>
    <p>La función de distribución acumulada o función de probabilidad acumulada de una variable aleatoria discreta es la probabilidad de que la variable aleatoria tome un valor menor o igual a un valor dado.</p>

    <li><h3>3.2 Variables aleatorias Continuas.</h3></li>
    <p>Las variables aleatorias continuas son aquellas que pueden tomar cualquier valor dentro de un intervalo, a diferencia de las variables aleatorias discretas que sólo pueden tomar valores específicos.</p>
        
    <li><h3>3.2.1 Distribución de probabilidad en forma general.</h3></li>
    <p>La distribución de probabilidad de una variable aleatoria continua es una función que asigna una densidad de probabilidad a cada posible valor de la variable.</p>

    <li><h3>3.2.2 Valor esperado</h3></li>
    <p>El valor esperado de una variable aleatoria continua es la integral del producto del valor de la variable y su función de densidad de probabilidad a lo largo de todo el rango de valores posibles.</p>

    <li><h3>3.2.3 Variancia, desviación estándar.</h3></li>
    <p> La variancia de una variable aleatoria continua es la integral del cuadrado de la diferencia entre el valor de la variable y su valor esperado, ponderada por la función de densidad de probabilidad. </p>
    <p>La desviación estándar es la raíz cuadrada positiva de la variancia.</p>

    <li><h3>3.2.4 Función acumulada.</h3></li>
    </p> La función de distribución acumulada o función de probabilidad acumulada de una variable aleatoria continua es la integral de la función de densidad de probabilidad desde menos infinito hasta el valor dado.</p>
   
    <li><h3>3.2.5 Cálculos de probabilidad.</h3></li>
    <p>Cálculos de probabilidad: Involucra el uso de la función de densidad de probabilidad o la función de distribución acumulada para calcular probabilidades de que la variable aleatoria continua tome valores en ciertos intervalos.</p>
</ul>

<ul>
<h2>Tema 4</h2>
<h2> Distribuciones de Probabilidad.</h2>


    <li><h3>4.1 Función de probabilidad:</h3></li>
    <p>La función de probabilidad es una función matemática que describe la probabilidad de que una variable aleatoria tome un determinado valor. Proporciona una representación formal de la distribución de probabilidad de una variable.</p>

    <li><h3>4.2 Distribución binomial:</h3></li>
    <p>La distribución binomial es una distribución de probabilidad discreta que modela el número de éxitos en una serie de n ensayos independientes, donde cada ensayo tiene solo dos posibles resultados, generalmente éxito o fracaso, y la probabilidad de éxito es constante.</p>
    <p>Función de probabilidad:</p>
    <ul>
        f(k;n,p)=(n) 
    </ul>

    <li><h3>4.3 Distribución hipergeométrica:</h3></li>
    <p>La distribución hipergeométrica es una distribución de probabilidad discreta que describe el número de éxitos en una muestra aleatoria sin reemplazo de una población finita. Se utiliza cuando la población tiene dos categorías y se extrae una muestra sin reemplazo.</p>

    <li><h3>4.4 Distribución de Poisson:</h3></li>
    <p>La distribución de Poisson es una distribución de probabilidad discreta que expresa la probabilidad de que ocurra un número determinado de eventos independientes en un intervalo de tiempo o espacio fijo, siempre que estos eventos ocurran con una velocidad o frecuencia media conocida.</p>

    <li><h3>4.5 Distribución normal:</h3></li>
    <p>La distribución normal, también conocida como distribución gaussiana, es una distribución de probabilidad continua que se caracteriza por tener una forma de campana simétrica alrededor de la media. Es muy importante en estadística y probabilidad debido a sus numerosas aplicaciones.</p>

    <li><h3>4.6 Distribución T-student:</h3></li>
    <p>La distribución T-student, o simplemente distribución t, es una distribución de probabilidad continua que se utiliza para hacer inferencias estadísticas cuando el tamaño de la muestra es pequeño y la desviación estándar de la población es desconocida.</p>

    <li><h3>4.7 Distribución Chi cuadrada:</h3></li>
    <p>La distribución Chi-cuadrada, o distribución ji-cuadrada, es una distribución de probabilidad continua que se utiliza para modelar la suma de los cuadrados de variables aleatorias normales estandarizadas e independientes.</p>

    <li><h3>4.8 Distribución F:</h3></li>
    <p>La distribución F, también conocida como distribución de Fisher-Snedecor, es una distribución de probabilidad continua que se utiliza para analizar la varianza de dos poblaciones normales e independientes. Se emplea en pruebas de hipótesis que involucran cocientes de varianzas.</p>
</ul>


<ul>
<h2>Tema 5</h2>
<h2>Regresión lineal.</h2>


<h3>5.1 Regresión y correlación</h3>
<p>La regresión y la correlación son dos conceptos estadísticos estrechamente relacionados que permiten estudiar la relación entre dos variables.</p>

<p>La <strong>regresión</strong> se enfoca en modelar la relación entre una variable dependiente (Y) y una o más variables independientes (X). El objetivo es encontrar un modelo matemático que permita predecir el valor de Y a partir de los valores de X.</p>

<p>Los principales tipos de regresión son:</p>
<ul>
  <li><strong>Regresión lineal simple</strong>: Cuando hay una sola variable independiente X.</li>
  <li><strong>Regresión lineal múltiple</strong>: Cuando hay varias variables independientes X1, X2, ..., Xk.</li>
  <li><strong>Regresión no lineal</strong>: Cuando la relación entre Y y X no es lineal.</li>
</ul>

<p>La <strong>correlación</strong>, por otro lado, mide el grado de relación lineal entre dos variables X e Y. El coeficiente de correlación (r) varía entre -1 y 1, y nos indica la fuerza y dirección de dicha relación:</p>
<ul>
  <li>r = 1 indica una correlación positiva perfecta</li>
  <li>r = -1 indica una correlación negativa perfecta</li>
  <li>r = 0 indica que no hay relación lineal entre las variables</li>
</ul>
<p>Valores cercanos a 1 o -1 indican una fuerte relación lineal, mientras que valores cercanos a 0 indican una relación débil o inexistente.</p>

<h3>5.1.1 Diagrama de dispersión</h3>
<p>Un diagrama de dispersión es una representación gráfica de los valores de dos variables, donde cada punto en el gráfico representa un par de valores observados de las dos variables. Este tipo de gráfico permite visualizar la relación entre las variables y determinar si existe una posible relación lineal entre ellas.</p>

<h3>5.1.2 Regresión lineal simple</h3>
<p>La regresión lineal simple es una técnica estadística utilizada para modelar la relación entre una variable dependiente (Y) y una variable independiente (X). El modelo de regresión lineal simple tiene la forma Y = a + bX, donde "a" es el intercepto y "b" es la pendiente de la recta de regresión. El objetivo es encontrar los valores de "a" y "b" que mejor se ajusten a los datos observados.</p>

<h3>5.1.3 Correlación</h3>
<p>La correlación mide el grado de asociación lineal entre dos variables. El coeficiente de correlación (r) varía entre -1 y 1, donde -1 indica una relación lineal negativa perfecta, 0 indica que no hay relación lineal, y 1 indica una relación lineal positiva perfecta.</p>

<h3>5.1.4 Determinación y análisis de los coeficientes de correlación y de determinación</h3>
<p>El coeficiente de determinación (r^2) mide la proporción de la varianza de la variable dependiente (Y) que es explicada por la variable independiente (X) en el modelo de regresión lineal simple. Varía entre 0 y 1, donde 0 indica que el modelo no explica nada de la varianza de Y, y 1 indica que el modelo explica toda la varianza de Y.</p>

<h3>5.1.5 Distribución normal bidimensional</h3>
<p>La distribución normal bidimensional describe la distribución conjunta de dos variables aleatorias que siguen una distribución normal. Esta distribución permite estudiar la relación entre las dos variables y calcular probabilidades conjuntas.</p>
</body>
</html>